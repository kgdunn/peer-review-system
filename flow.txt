* Statistics: getting review
* Statistics: getting grades

* Renew HTTPs certificate

* See their progress in the peer/self review process: xx % completed
* Push the grades back to Brightspace
* Standard deviation of std. deviation to Conny
* Show in the admin interface the avg time take on the rubric

https://community.brightspace.com/devcop/blog/setting_up_an_lti_11_integration_in_brightspace


* What was the effect of self-review? Did reports improve?
* Send ZIP file of all practicum reports: self-review and peer-review

* Model to store grade reports in the database; with a flag to capture updates

* Keep students informed on how many completed reviews have been done on their
work.
* Instructor sees how many reviews each student has done, and the status of
reviews.
* Students don't get a grade if they have not submitted peer review'

* Show admin's grades as soon as they graded

* How the correlation of the instructors matches up with the students.
* D3JS histogram of the grades for the students
* Add a "header" section inbetween items. To divide sections up.
* Add XHR for checkbox items
* Get on a per-item basis, the std dev for Conny to help to improve rubric.
* Calculate the colour coded correlation (coloured by instructor name)

Show progress of work done on a page (NN% completed)
Save the r_actual at every XHR, so the .modified field is updated.
Show r_actual in group.ID order, or submission order
Check that peer feedback results are the correct ones



* Log the XHR events with Statistics still

* Completed submissions via an intermediate database table

    # And also mark the submission as having one extra submission:
    #r_actual.submission.number_reviews_completed += 1
    #r_actual.submission.status = 'G' # in progress
    #r_actual.submission.save()

    # Reviews to still complete by this learner:
    #n_graded_already = RubricActual.objects.filter(graded_by=learner,
    #                                               status='C').count()
    #phase = r_actual.rubric_template.phase
    #n_to_do = max(0, get_n_reviews(learner, phase) - n_graded_already)


TO DO
======

* Does it matter that there are duplicate "Enrolled" instances?
* Don't allow non-PDF for upload
* Return error messages for non-PDF; too large files

Groups
--------
Open time
Closing time
Allow more than N enrollments
Groups of different sizes
Can be prefilled
Allow self-removal and re-enrollment
Longer term: waitlist
Export to CSV
IMport names from CSV
Show description of groups
Log for administrator

Upload
=-------
Add upload bar: https://github.com/ouhouhsami/django-progressbarupload
Size limit
Strip out the PDF information
Check for PDF
>>> import magic
>>> magic.from_file("testdata/test.pdf")


To do next
-----------
Add the group name in the email to the students.
Prominently colour "Submit" button. Orange when not submitted; Green when submitted.
After cut-off time show calculation of their grades


During the run:
----
Watch the reviews coming in at: https://peer.connectmv.com/admin/review/roptionactual/
Track linode stats
Run htop
Dump the data to text file:
  ./manage.py dumpdata review stats --format=json --indent=2 > backup-`date '+%Y-%m-%d-%H-%M-%S'`.json


Review process
==============
Use the LTI checker: http://ltiapps.net/test/tc.php
https://github.com/Brightspace/sample-LTI-WHMIS-quiz
Send grades back:
https://community.brightspace.com/devcop/blog/so_you_want_to_extend_your_lms__part_1_lti_primer

To send back grades once a student has completed an assessment in a learning tool, the tool sends an HTTP POST back to the LMS via the URL specified in the [lis_outcome_service_url] field, the payload being a block of XML that contains the grade details.

<?xml version = "1.0" encoding = "UTF-8"?>
<imsx_POXEnvelopeRequest xmlns = "http://www.imsglobal.org/services/ltiv1p1/xsd/imsoms_v1p0">
  <imsx_POXHeader>
    <imsx_POXRequestHeaderInfo>
      <imsx_version>V1.0</imsx_version>
      <imsx_messageIdentifier>51b8cdfc2a7bb</imsx_messageIdentifier>
    </imsx_POXRequestHeaderInfo>
  </imsx_POXHeader>
  <imsx_POXBody>
    <replaceResultRequest>
      <resultRecord>
        <sourcedGUID>
          <sourcedId>8d053b33-6f1f-410c-888b-1944226e44d3</sourcedId>
        </sourcedGUID>
        <result>
          <resultScore>
            <language>en-us</language>
            <textString>0.33</textString>
          </resultScore>
        </result>
      </resultRecord>
    </replaceResultRequest>
  </imsx_POXBody>
</imsx_POXEnvelopeRequest>


Look at extending it with a remote plugin:
http://docs.valence.desire2learn.com/ui-ext/rplugins.html